{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory applied machine learning (INFR10069) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Neural Networks\n",
    "\n",
    "In this lab we will perform classification on handwritten digits. We will use the UCI Pen-Based Recognition of Handwritten Digits Data Set, which you can read more about below.\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Dataset exploration\n",
    "\n",
    "In this part we will familiarize ourselves with the dataset. Run the below cell to load the digits dataset directly from scikit.\n",
    "\n",
    "The digits dataset contains images of handwritten digits and their corresponding class. We will train classifiers to predict which digit is in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The digits dataset\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.1 ==========\n",
    "\n",
    "Create a pandas dataframe from the digits dataset. You might find it useful to inspect the result of the `.keys()` function to see what's in the the `digits` dataset.\n",
    "\n",
    "1. How many features do the images have?\n",
    "2. What is the difference between the `data` and `images` fields?\n",
    "\n",
    "Label the features `X1` - `XN`, where `N` is the number of features. Label the target `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.2 ==========\n",
    "\n",
    "Use the `.describe()` function on the data frame. What does the mean of each feature tell us about the images? Do all the features carry the same amount of information? \n",
    "\n",
    "What do you expect the mean of `y` to be if the dataset is balanced? If so, is this enough information to justify that the dataset is balanced or do we need something more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.3 ==========\n",
    "\n",
    "Use `plt.imshow()` to visualize the images in the below figure. The function takes a 2D array as input.\n",
    "\n",
    "Plot the images with index 1, 101, 50, and 750."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.4 ==========\n",
    "\n",
    "Use `plt.imshow()` to visualize the `mean` and standard deviation (`std`) of the images in the entire dataset. What do you notice about the corner pixels in the image? What does that tell us about the amount of information they give us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.5 ==========\n",
    "\n",
    "Crate a `train`, `test` *and* `validation` split from the data. Use a 60/20/20 split for train/test/validation.\n",
    "\n",
    "*Hint*: You can use the inbuilt sklearn function `train_test_split` twice, once on the original dataset and once on the resulting set to create the split.\n",
    "\n",
    "Use `random_seed=42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Multiclass Linear Model\n",
    "\n",
    "For our baseline, we will use a [LogisticRegression model](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), which you used in [Lab 03 - Classification and Evaluation](https://github.com/uoe-iaml/iaml-labs/blob/master/Labs/03%20-%20Classification%20and%20Evaluation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ========== Question 2.1 ==========\n",
    "Familiarize yourself with the `multi_class` parameter in the LogisticRegression function to train a one-versus-rest multi-class classifier on the training data.\n",
    "\n",
    "Use `accuracy_score` to report the accuracy on thetest set. Did you expect the performance to be this good or bad? Why or why not?\n",
    "\n",
    "Again, use `random_state=42`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Classification with Neural Networks\n",
    "\n",
    "In this part, we will use [Scikit's MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) to train a neural network to classify the handwritten digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 3.1 ==========\n",
    "\n",
    "Initialize an MLPClassifier with one hidden layer consisting of 50 neurons, and set early_stopping=True and fit the neural network to the training data. You can leave the other parameters to the default settings. Is the performance better than the linear classifier?\n",
    "\n",
    "As usual, set `random_state=42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 3.2 ==========\n",
    "\n",
    "In this part, we will perform a grid search over a few of the `MLPClassifier` parameters. Namely, we will look at\n",
    "\n",
    "- `hidden_layer_sizes`\n",
    "- `activation`\n",
    "- `alpha`\n",
    "- `momentum`\n",
    "\n",
    "Familiarize yourself with the meaning of the above parameters. If you are curious, here is an in-depth, yet very accessible [article on momentum](https://distill.pub/2017/momentum/).\n",
    "\n",
    "Then initialize a dictionary that has as keys the above parameters and the following ranges for each\n",
    "\n",
    "- `hidden_layer_sizes`: 16, 32, 64, 128, 256\n",
    "- `batch_size`: 64, 128, 256, 512\n",
    "\n",
    "There are other parameters we could potential vary. Optionally, after you have completed the rest of the lab, you can try to vary the following. Make sure you read the documentation and know what the values mean first!\n",
    "- `activation`: `relu` and `logistic`\n",
    "- `alpha`: 1e-3, 1e-4, 1e-5\n",
    "\n",
    "This dictionary will be used in the provided code for 3.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 3.3 ==========\n",
    "\n",
    "In this part, we will use [ParameterGrid](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html) to loop over all possible combinations of settings for the grid search.\n",
    "\n",
    "Fill in the missing code to instantiate an `MLPClassifier` with the given parameters and fit it on the data.\n",
    "\n",
    "You can use the `.set_params()` method after you have instantiated the `MLPClassifier`. Set `tol=1e-3`, `solver='adam'`, `random_state=42`, and `max_iter=1000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_results = []\n",
    "\n",
    "for g in ParameterGrid(grid):\n",
    "    # Your code goes here\n",
    "    #   Initialize an MLPClassifier and train it on the *training set*\n",
    "    \n",
    "    grid_search_results.append({\n",
    "        'mlp': mlp,\n",
    "        'params': g,\n",
    "        # Your code goes here\n",
    "        'train_score': # compute the training set accuracy score\n",
    "        'val_score': # compute the validation set accuracy score\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 3.4 ==========\n",
    "\n",
    "In this part, we will plot the effects of hidden layer sizes on accuracy. We will compute the mean accuracy and a standard deviation for each hidden layer size over other parameter changes. In other words, if `hidden_layer_sizes=50`, we have `4` (or `18`, if you varied `activation` and `alpha`) accuracy scores, one for each of the other parameters.\n",
    "\n",
    "Read the plotting code below and write code that computes summary statistics from the results of the grid search.\n",
    "\n",
    "The summary statistics we will look at are the mean and standard deviation of accuracy scores on the training and validation datasets (`train_score` and `val_score` as stored above in `grid_search_results`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores_val, std_scores_val = [], []\n",
    "mean_scores_train, std_scores_train = [], []\n",
    "\n",
    "for ls in grid['hidden_layer_sizes']:\n",
    "    mean_scores_val.append(\n",
    "        np.mean([\n",
    "            x['val_score'] for x in grid_search_results if x['params']['hidden_layer_sizes'] == ls\n",
    "        ])\n",
    "    )\n",
    "    std_scores_val.append(\n",
    "        np.std([\n",
    "            x['val_score'] for x in grid_search_results if x['params']['hidden_layer_sizes'] == ls\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    # Your code goes here.\n",
    "    #  compute the mean and standard deviation on the train set for\n",
    "    #  all classifiers where hidden_layer_sizes=ls\n",
    "\n",
    "mean_scores_val = np.array(mean_scores_val)\n",
    "std_scores_val = np.array(std_scores_val)\n",
    "\n",
    "mean_scores_train = np.array(mean_scores_train)\n",
    "std_scores_train = np.array(std_scores_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "plt.rcParams['font.size'] = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "plt.plot(grid['hidden_layer_sizes'], mean_scores_train, color=cm[0])\n",
    "plt.scatter(grid['hidden_layer_sizes'], mean_scores_train, label='Train score',  color=cm[0])\n",
    "plt.fill_between(\n",
    "    grid['hidden_layer_sizes'],\n",
    "    mean_scores_train - std_scores_train, mean_scores_train + std_scores_train,\n",
    "    alpha=0.3, color=cm[0]\n",
    ")\n",
    "\n",
    "\n",
    "plt.plot(grid['hidden_layer_sizes'], mean_scores_val, color=cm[1])\n",
    "plt.scatter(grid['hidden_layer_sizes'], mean_scores_val, label='Val. score', color=cm[1])\n",
    "plt.fill_between(\n",
    "    grid['hidden_layer_sizes'],\n",
    "    mean_scores_val - std_scores_val, mean_scores_val + std_scores_val,\n",
    "    alpha=0.2, color=cm[1]\n",
    ")\n",
    "\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.xlabel('Hidden layer size')\n",
    "plt.ylabel('Accuracy score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 3.4 ==========\n",
    "\n",
    "Finally, pick the best classifier based on the accuracy score on the validation set.\n",
    "\n",
    "You can use python's sorted, [which can additionally use a key function](https://docs.python.org/3/howto/sorting.html#key-functions). \n",
    "\n",
    "Lastly, report the score of the best classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Feature Importance\n",
    "\n",
    "In this part, we will randomize a feature and look at its effect on classification. This way we can reason about how important a feature is for classification. If the performance stays the same when the feature is removed (or randomized), then we can reason it has low importance and vice-versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 4.1 ==========\n",
    "\n",
    "Randomize the top-left pixel (index 0) in each image in the test set, then use the `MLPClassifier` with the best settings found above by the grid search. Report the test-set accuracy of the already trained model.\n",
    "\n",
    "To randomize, generate a uniform random number by calling [np.random.uniform](https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html). You need to specify the range -- you can use `np.min` and `np.max` on the original dataset to get the correct values.\n",
    "\n",
    "Note in this case we are not selecting a model, rather looking at performance, so we are not using a validation set at all.\n",
    "\n",
    "*Hint*: You can use numpy's [np.copy](https://numpy.org/doc/stable/reference/generated/numpy.copy.html) to copy the train set so you don't overwrite your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set numpy's seed so that we obtain reproducible results\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the performance change and by how much? Can you explain the difference?\n",
    "\n",
    "*Hint:* Go back to the start of the lab where we used `.describe()` on the dataframe you created. Look at the values of the top-left pixel in the original array. What do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 4.2 ==========\n",
    "\n",
    "Now randomize all the pixels, *one at a time*. For each pixel, record the ratio of the best accuracy score to the one obtained. Use `.imshow()` to plot a 2D grid of the importances for each pixel.\n",
    "\n",
    "Which pixel is the least/most important? Do you have any intuition why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
